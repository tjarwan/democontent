<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title/><link rel="stylesheet" href="../css/base.min.css"/><link rel="stylesheet" href="../css/fancy.min.css"/><link rel="stylesheet" href="../css/pdf.css"/><meta name="viewport" content="width=640, height=824"/></head><body><div id="page_body"><div id="pf71" class="pf w2 h2" data-page-no="71"><div class="pc pc71 w2 h2"><img class="bi x28 ya1b w4 h46" alt="" src="bg71.png"/><div class="t m0 x29 h10 y83 ff1 fs9 fc0 sc0 lsa ws0">90<span class="_ _d"> </span><span class="ff2 fs2 ls8">Advanced Persistent Threat Hacking<span class="_ _1e"/> </span></div><div class="t m0 x24 h1d y1cc ff1 fs7 fc0 sc0 ls0 ws0">Location<span class="_ _4b"> </span>W<span class="_ _0"/>ord Count</div><div class="t m0 x24 h6 y1cd ff4 fs2 fc0 sc0 ls0 ws0">/usr/share/dnsrecon/namelist.txt<span class="_ _4c"> </span>1,907</div><div class="t m0 x24 h6 ya1c ff4 fs2 fc0 sc0 ls0 ws0">/usr/share/dnsenum/dns.txt<span class="_ _4d"> </span>1,480</div><div class="t m0 x24 h6 ya1d ff4 fs2 fc0 sc0 ls0 ws0">/usr/share/dnsenum/dns-big.txt<span class="_ _4e"> </span> 266,930</div><div class="t m0 x24 h6 ya1e ff4 fs2 fc0 sc0 ls0 ws26">/usr/share/dnsmap/wordlist_TLAs.txt 17,576</div><div class="t m0 x16 hd ya1f ff4 fs7 fc0 sc0 ls0 ws0">Thanks to the work of Ryan De<span class="_ _0"/>whurst of de<span class="_ _0"/>whurstsecurity<span class="_ _2"/>.com, we hav<span class="_ _0"/>e some </div><div class="t m0 x28 hd ya20 ff4 fs7 fc0 sc0 ls0 ws0">very good options for brute-forcing domain names. Ryan used data obtained </div><div class="t m0 x28 hd ya21 ff4 fs7 fc0 sc0 ls0 ws0">from <span class="_ _2"/>Alexa.com, which provides the top 1 million most popular websites on the </div><div class="t m0 x28 hd ya22 ff4 fs7 fc0 sc0 lsb ws16">Internet daily<span class="_ _2"/>. He then attempted zone transfers against these domains. Despite only </div><div class="t m0 x28 hd ya23 ff4 fs7 fc0 sc0 lsb ws16">being able to perform zone transfers against roughly 6 percent (that’<span class="_ _2"/>s over 60,000 </div><div class="t m0 x28 hd ya24 ff4 fs7 fc0 sc0 ls0 ws0">domains), he was able to b<span class="_ _0"/>uild an impressi<span class="_ _0"/>ve list of the most common host records. </div><div class="t m0 x28 hd ya25 ff4 fs7 fc0 sc0 ls0 ws0">I highly recommend you do<span class="_ _0"/>wnload the wordlists and put them to use, as well as </div><div class="t m0 x28 hd ya26 ff4 fs7 fc0 sc0 ls0 ws0">analyze the contents of the les.</div><div class="t m0 x24 h1d ya27 ff1 fs7 fc0 sc0 ls0 ws0">Name<span class="_ _4f"> </span>W<span class="_ _0"/>ord Count<span class="_ _50"> </span>Size</div><div class="t m0 x24 h6 ya28 ff4 fs2 fc0 sc0 ls0 ws0">subdomains-top1mil-5000.txt<span class="_ _31"> </span>5,000<span class="_ _51"> </span>33KB</div><div class="t m0 x24 h6 ya29 ff4 fs2 fc0 sc0 ls0 ws0">subdomains-top1mil-20000.txt<span class="_ _52"> </span>20,000<span class="_ _53"> </span>146KB</div><div class="t m0 x24 h6 ya2a ff4 fs2 fc0 sc0 ls0 ws0">subdomains-top1mil.txt<span class="_ _3b"> </span>114,606<span class="_ _54"> </span>1.1MB</div><div class="t m0 x24 h6 ya2b ff4 fs2 fc0 sc0 ls0 ws0">subdomains-top1mil-with-rank.txt<span class="_ _55"> </span>2,954,195<span class="_ _56"> </span>42MB</div><div class="t m0 x16 hd ya2c ff4 fs7 fc0 sc0 ls0 ws0">Even better<span class="_ _2"/>, these les are now included with the latest version of dnsrecon. If you </div><div class="t m0 x28 hd ya2d ff4 fs7 fc0 sc0 ls0 ws0">hav<span class="_ _0"/>e the git client installed on your computer<span class="_ _0"/>, you can grab the latest dnsrecon with </div><div class="t m0 x28 hd ya2e ff4 fs7 fc0 sc0 ls0 ws0">the follo<span class="_ _0"/>wing command:</div><div class="t m0 x28 h44 ya2f fff fse fc0 sc0 ls0 ws0">git clone https://github.com/darkoperator/dnsrecon</div><div class="t m0 x28 h7 ya30 ff1 fs3 fc0 sc0 ls0 ws0">Domain Harvesting</div><div class="t m0 x28 hd ya31 ff4 fs7 fc0 sc0 ls0 ws0">Another great way for us to identify as man<span class="_ _0"/>y hosts as possible is by harvesting DNS </div><div class="t m0 x28 hd ya32 ff4 fs7 fc0 sc0 ls0 ws0">names from websites. <span class="_ _0"/>W<span class="_ _3"/>e can do this manually<span class="_ _0"/>, although thankfully<span class="_ _2"/>, there are a </div><div class="t m0 x28 hd ya33 ff4 fs7 fc0 sc0 ls0 ws0">handful of tools to help us with this as well. Using dnsrecon and the -t goo option, </div><div class="t m0 x28 hd ya34 ff4 fs7 fc0 sc0 ls0 ws0">we can scrape Google for any hostnames found in our tar<span class="_ _0"/>get domain.</div><div class="t m0 x16 hd ya35 ff4 fs7 fc0 sc0 ls0 ws0">W<span class="_ _3"/>e can also use a tool called theharvester to harvest domain names. Not only </div><div class="t m0 x28 hd ya36 ff4 fs7 fc0 sc0 ls0 ws0">does theharvester allo<span class="_ _0"/>w us to harv<span class="_ _0"/>est more than just domain names, but we can also </div><div class="t m0 x28 hd ya37 ff4 fs7 fc0 sc0 ls0 ws0">search other popular data sources besides Google for domain names. Currently<span class="_ _2"/>, </div><div class="t m0 x28 hd ya38 ff4 fs7 fc0 sc0 lsb ws16">theharvester supports the follo<span class="_ _0"/>wing data sources: Google, Bing, bingapi, pgp, </div><a class="" href="http://dewhurstsecurity.com"><div class="d m1" style="border-style:none;position:absolute;left:323.023432px;bottom:586.594104px;width:98.000000px;height:12.000000px;background-color:rgba(255,255,255,0.000001);"/></a><a class="" href="http://Alexa.com"><div class="d m1" style="border-style:none;position:absolute;left:116.220711px;bottom:555.150416px;width:50.000000px;height:12.000000px;background-color:rgba(255,255,255,0.000001);"/></a></div><div class="pi" data-data="{&#34;ctm&#34;:[1.209373,0.000000,0.000000,1.209373,0.000000,0.000000]}"/></div></div></body></html>