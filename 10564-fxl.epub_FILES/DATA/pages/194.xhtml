<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xsi:schemaLocation="http://www.w3.org/MarkUp/SCHEMA/xhtml11.xsd" xml:lang="en">
<head>
 <title>Test document here</title>

<link rel="stylesheet" href="../css/base.min.css"/>
<link rel="stylesheet" href="../css/fancy.min.css"/>
<link rel="stylesheet" href="../css/pdf.css"/>
<meta name="viewport" content="width=640, height=824"/>
</head>
<body>
<div id="page_body">
<div id="pfc2" class="pf w0 h0" data-page-no="c2"><div class="pc pcc2 w0 h0"><div class="t m0 x76 h5 y5a ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x81 h5 y26f ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x7a h5 y270 ff39 fs2 fc0 sc0 ls0 ws0"> <span class="_ _4"></span> </div><div class="t m0 xbb h5 y6b7 ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x3e h5 y9d5 ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xfa h5 y9d6 ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x4a h5 y9d7 ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x0 h3 y9d8 ff3a fs2 fc0 sc0 ls0 ws0"> <span class="_ _4"></span> </div><div class="t m0 x0 h5 y6ba ff39 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xc4 h2 ya5 ff3a fs1 fc1 sc0 ls0 ws0">203 <span class="_ _1e"></span>The Complementarity of Models and Language </div><div class="t m0 x76 h5 y5a ff39 fs2 fc1 sc0 ls7 wsa68">As a consequence, advocates of the computational theory of mind tend </div><div class="t m0 x0 h5 y5b ff39 fs2 fc1 sc0 ls7 ws915">to mix together two very different types of claims about the mind. (I do not </div><div class="t m0 x0 h5 y102 ff39 fs2 fc1 sc0 ls7 ws2dd">mean to imply that they conflate them, though I am trying to caution the </div><div class="t m0 x0 h5 y103 ff39 fs2 fc1 sc0 ls7 ws1d4">reader not to do so.) On the one hand, computationalists often claim that </div><div class="t m0 x0 h5 y104 ff39 fs2 fc1 sc0 ls7 ws181">intentional states like beliefs and desires involve “mental representations” </div><div class="t m0 x0 h5 y105 ff39 fs2 fc1 sc0 ls11 ws3fc">that are at least closely analogous to structures in natural languages—say<span class="_ _2d"></span>, </div><div class="t m0 x0 h5 y106 ff39 fs2 fc1 sc0 ls11 ws20e">that intentional states are functional relations to representations with a </div><div class="t m0 x0 h5 y107 ff39 fs2 fc1 sc0 ls7 ws721">compositional syntax that has a subject-predicate structure. On the other </div><div class="t m0 x0 h5 y108 ff39 fs2 fc1 sc0 ls7 ws840">hand, they also claim that thinking in general is couched in some form </div><div class="t m0 x0 h5 y109 ff39 fs2 fc1 sc0 ls7 ws50f">of symbolic representation and driven by “syntactic” (i.e., nonsemantic) </div><div class="t m0 x0 h5 y10a ff39 fs2 fc1 sc0 ls7 ws85a">processes, presumably at some more fundamental level analogous to the </div><div class="t m0 x0 h5 y10b ff39 fs2 fc1 sc0 ls7 ws5bf">machine code of a digital computer<span class="_ _2"></span>, with allowances made for the dif-</div><div class="t m0 x0 h5 y10c ff39 fs2 fc1 sc0 ls7 ws788">ferences between the “implementing” systems of chips and neurons. The </div><div class="t m0 x0 h5 y10d ff39 fs2 fc1 sc0 ls7 ws986">latter claim does not apply only to intentional states we humans experi-</div><div class="t m0 x0 h5 y10e ff39 fs2 fc1 sc0 ls7 ws9ce">ence, such as judgments. If human cognition is “computational” in this </div><div class="t m0 x0 h5 y10f ff39 fs2 fc1 sc0 ls7 ws5e5">sense, presumably the cognitive processes of crocodiles and butterflies are </div><div class="t m0 x0 h5 y110 ff39 fs2 fc1 sc0 ls7 ws2b8">“computational” as well, though the “computations” are simpler and per-</div><div class="t m0 x0 h5 y111 ff39 fs2 fc1 sc0 ls7 ws957">haps couched in the different “machine languages” of different types of </div><div class="t m0 x0 h5 y112 ff39 fs2 fc1 sc0 ls7 ws6fd">brains. But if this is true, the claim that thought is computational does </div><div class="t m0 x0 h5 y113 ff39 fs2 fc1 sc0 ls7 ws28a">not imply that it is structurally language-like. And if some language-like </div><div class="t m0 x0 h5 y114 ff39 fs2 fc1 sc0 ls7 ws6f2">structures are built on such “machine-level” architectures, we have no rea-</div><div class="t m0 x0 h5 y115 ff39 fs2 fc1 sc0 ls7 ws439">son to suppose that any <span class="ff3b ws0">semantic</span><span class="ls11 ws247"> properties of the system supervene on </span></div><div class="t m0 x0 h5 y116 ff39 fs2 fc1 sc0 ls7 ws209">their specifically language-like form. It might instead be a consequence of </div><div class="t m0 x0 h5 y117 ff39 fs2 fc1 sc0 ls7 ws380">other structures that can be built on the machine-level architecture, such </div><div class="t m0 x0 h5 y118 ff39 fs2 fc1 sc0 ls7 ws778">as frames or models. So even if we grant (1) that cognitive processes are </div><div class="t m0 x0 h5 y119 ff39 fs2 fc1 sc0 ls7 wsa69">accomplished through “computation” (in the machine-level sense), <span class="ff3b ws0">and </span></div><div class="t m0 x0 h5 y11a ff39 fs2 fc1 sc0 ls7 ws576">(2) that structurally language-like systems are built out of machine-level </div><div class="t m0 x0 h5 y11b ff39 fs2 fc1 sc0 ls7 ws9c2">computational resources, <span class="_ _29"></span><span class="ff3b ws0">and<span class="ff39 ws9c2"> (3) that some sorts of data structures and </span></span></div><div class="t m0 x0 h5 y11c ff39 fs2 fc1 sc0 ls7 wsa6a">machine-level computational processes can, in the right configurations, </div><div class="t m0 x0 h5 y11d ff39 fs2 fc1 sc0 ls7 ws30e">confer (or at least mimic) semantic understanding,</div><div class="t m0 xa3 h8 y90 ff39 fs4 fc1 sc0 ls0 ws0">1</div><div class="t m0 x3e h5 y138 ff39 fs2 fc1 sc0 ls11 ws5b4"> it does not follow from </div><div class="t m0 x0 h5 y9d9 ff39 fs2 fc1 sc0 ls7 ws664">this that the <span class="ff3b ws0">kinds</span> of data structures and machine-level processes that con-</div><div class="t m0 x0 h5 y2d9 ff39 fs2 fc1 sc0 ls7 ws3cc">fer understanding are the ones that are structurally language-like. Indeed, </div><div class="t m0 x0 h5 y5fd ff39 fs2 fc1 sc0 ls7 ws491">the very concerns that led to the development of structures like semantic </div><div class="t m0 x0 h5 y5fe ff39 fs2 fc1 sc0 ls7 wsa6b">networks and frames suggest that any semblance of understanding that </div><div class="t m0 x0 h5 y3e3 ff39 fs2 fc1 sc0 ls7 wsa33">can be programmed into computers requires model-like, rather than lan-</div><div class="t m0 x0 h5 y57e ff39 fs2 fc1 sc0 ls11 ws84d">guage-like, structures. </div><div class="t m0 x0 h3 y9da ff3a fs2 fc1 sc0 ls11 ws3d">Causal Semantics </div><div class="t m0 x0 h5 y9db ff39 fs2 fc1 sc0 ls11 ws481">Since the influential publications of Putnam (1975) and Kripke (1980), a </div><div class="t m0 x0 h5 y6aa ff39 fs2 fc1 sc0 ls7 ws4ce">great deal of philosophical work in semantics has concentrated on how the </div></div><div class="pi" data-data='{"ctm":[1.271605,0.000000,0.000000,1.271605,0.000000,0.000000]}'></div></div>
</div>
</body>
</html>
