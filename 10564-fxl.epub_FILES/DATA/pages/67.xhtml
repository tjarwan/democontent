<?xml version='1.0' encoding='utf-8'?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
 xsi:schemaLocation="http://www.w3.org/MarkUp/SCHEMA/xhtml11.xsd" xml:lang="en">
<head>
 <title>Test document here</title>

<link rel="stylesheet" href="../css/base.min.css"/>
<link rel="stylesheet" href="../css/fancy.min.css"/>
<link rel="stylesheet" href="../css/pdf.css"/>
<meta name="viewport" content="width=640, height=824"/>
</head>
<body>
<div id="page_body">
<div id="pf43" class="pf w0 h0" data-page-no="43"><div class="pc pc43 w0 h0"><div class="t m0 x76 h5 y5e ff14 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xbf h5 y224 ff14 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x76 h5 y4ca ff14 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x76 h5 y17f ff14 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x76 h5 y4cb ff14 fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x0 h2 ya5 ff15 fs1 fc1 sc0 ls0 ws0">62 <span class="_ _44"> </span>Chapter 4 </div><div class="t m0 x0 h5 y5a ff14 fs2 fc1 sc0 ls7 ws5cb">based on explicit conscious reasoning. In these ways, they have much in </div><div class="t m0 x0 h5 y5b ff14 fs2 fc1 sc0 ls11 ws3d">common with Fodorian modules. </div><div class="t m0 x76 h5 y102 ff14 fs2 fc1 sc0 ls7 ws5cc">W<span class="_ _2e"></span>ith respect to some of Fodor’<span class="_ _2"></span>s other criteria, they differ from one </div><div class="t m0 x0 h5 y103 ff14 fs2 fc1 sc0 ls7 ws5cd">another: core systems are highly developmentally canalized, folk theories </div><div class="t m0 x0 h5 y104 ff14 fs2 fc1 sc0 ls7 ws5ce">are canalized as well but require a great deal of training and bootstrap-</div><div class="t m0 x0 h5 y105 ff14 fs2 fc1 sc0 ls7 ws3b">ping, while scientific theories are products of specialized learning, usually </div><div class="t m0 x0 h5 y106 ff14 fs2 fc1 sc0 ls7 ws5cf">requiring invention or instruction. Core and folk systems, but not scientific </div><div class="t m0 x0 h5 y107 ff14 fs2 fc1 sc0 ls7 ws272">theories, are plausibly products of evolution and may have species-typical </div><div class="t m0 x0 h5 y108 ff14 fs2 fc1 sc0 ls7 ws7d">neural realizations. It would seem that the mind has <span class="ff16 ws0">some</span> uses for domain-</div><div class="t m0 x0 h5 y109 ff14 fs2 fc1 sc0 ls7 ws1c8">specific understanding that is not modular in Fodor’<span class="_ _2"></span>s sense. But perhaps it </div><div class="t m0 x0 h5 y10a ff14 fs2 fc1 sc0 ls7 ws559">is too early to draw general conclusions from this, as core systems, folk the-</div><div class="t m0 x0 h5 y10b ff14 fs2 fc1 sc0 ls7 wsf2">ories, and scientific theories, while clearly “mental” in ways that perceptual </div><div class="t m0 x0 h5 y10c ff14 fs2 fc1 sc0 ls7 ws26b">input processors are not, are each rather special forms of cognition, in the </div><div class="t m0 x0 h5 y10d ff14 fs2 fc1 sc0 ls7 ws4dd">first two cases distinguished by their early appearance and developmental </div><div class="t m0 x0 h5 y10e ff14 fs2 fc1 sc0 ls7 ws0">canalization, and in the latter by the specialized learning required. </div><div class="t m0 x76 h5 y10f ff14 fs2 fc1 sc0 ls7 ws4c7">But in fact we have good reason to think that domain-sized units of </div><div class="t m0 x0 h5 y110 ff14 fs2 fc1 sc0 ls7 ws387">understanding, with proprietary ways of representing domains and tight </div><div class="t m0 x0 h5 y111 ff14 fs2 fc1 sc0 ls7 ws307">connections between concepts and inference patterns within the domain </div><div class="t m0 x0 h5 y112 ff14 fs2 fc1 sc0 ls7 ws348">but much looser connections across domain boundaries, are found broadly </div><div class="t m0 x0 h5 y113 ff14 fs2 fc1 sc0 ls7 ws136">within what Fodor would classify as central cognition. They would seem to </div><div class="t m0 x0 h5 y114 ff14 fs2 fc1 sc0 ls7 ws5d0">be, among other things, the basis for semantically based reasoning and intu-</div><div class="t m0 x0 h5 y115 ff14 fs2 fc1 sc0 ls7 ws5d1">itive inference. One reason for thinking this might be so is that researchers </div><div class="t m0 x0 h5 y116 ff14 fs2 fc1 sc0 ls7 ws399">in artificial intelligence, who started out trying to simulate human cogni-</div><div class="t m0 x0 h5 y117 ff14 fs2 fc1 sc0 ls7 ws109">tive abilities on the model of explicit reasoning in something like central </div><div class="t m0 x0 h5 y118 ff14 fs2 fc1 sc0 ls7 ws58e">cognition, ended up having to turn to theories positing domain-specific </div><div class="t m0 x0 h5 y119 ff14 fs2 fc1 sc0 ls7 ws0">understanding to explain everyday intuitive reasoning abilities. </div><div class="t m0 x76 h5 y11a ff14 fs2 fc1 sc0 ls11 ws5d2">Artificial intelligence emerged as a discipline fast on the heels of T<span class="_ _2"></span>uring’<span class="_ _2"></span>s </div><div class="t m0 x0 h5 y11b ff14 fs2 fc1 sc0 ls7 ws5d3">seminal discussion of digital computation. The first projects in AI were still </div><div class="t m0 x0 h5 y11c ff14 fs2 fc1 sc0 ls7 ws5d4">closely tied to computation’<span class="_ _2"></span>s mathematical heritage. They were automated </div><div class="t m0 x0 h5 y11d ff14 fs2 fc1 sc0 ls7 ws5d5">theorem provers like Newell and Simon’<span class="_ _2"></span>s (1956) Logic Theory Machine. </div><div class="t m0 x0 h5 y11e ff14 fs2 fc1 sc0 ls7 ws5d6">The viability of theorem-proving computers was already assured in prin-</div><div class="t m0 x0 h5 y147 ff14 fs2 fc1 sc0 ls7 ws192">ciple by T<span class="_ _2"></span>uring’<span class="_ _2"></span>s theoretical work. A computer can execute any formalized </div><div class="t m0 x0 h5 y148 ff14 fs2 fc1 sc0 ls7 ws5d7">algorithm, and so any proof that can be carried out by formal means can in </div><div class="t m0 x0 h5 y149 ff14 fs2 fc1 sc0 ls7 ws5d8">principle be proved by a computing machine. Researchers then attempted </div><div class="t m0 x0 h5 y14a ff14 fs2 fc1 sc0 ls7 ws191">to model human formal reasoning more generally<span class="_ _2d"></span>, in systems like General </div><div class="t m0 x0 h5 y14b ff14 fs2 fc1 sc0 ls7 wse9">Problem Solver (Newell, Shaw<span class="_ _2d"></span>, and Simon 1959). Such work is often viewed </div><div class="t m0 x0 h5 y14c ff14 fs2 fc1 sc0 ls11 ws3d">as the first generation of AI. </div><div class="t m0 x76 h5 y14d ff14 fs2 fc1 sc0 ls7 ws5d9">In attempting to model human reasoning more generally<span class="_ _2d"></span>, however<span class="_ _2e"></span>, AI </div><div class="t m0 x0 h5 y14e ff14 fs2 fc1 sc0 ls7 ws5da">researchers quickly hit an important roadblock. Precisely because formal rea-</div><div class="t m0 x0 h5 y14f ff14 fs2 fc1 sc0 ls7 ws5db">soning techniques abstract away from the semantic values of the symbols, </div></div><div class="pi" data-data='{"ctm":[1.271605,0.000000,0.000000,1.271605,0.000000,0.000000]}'></div></div>
</div>
</body>
</html>
